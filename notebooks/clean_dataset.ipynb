{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(\"exam_dataset_50k_unclean.csv\", low_memory=False)\n",
    "print(f\"  Raw shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standardise NULL representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 1: Replacing junk null representations with NaN...\")\n",
    "\n",
    "NULL_VALUES = {\"N/A\", \"n/a\", \"NA\", \"na\", \"NULL\", \"null\", \"None\", \"none\",\n",
    "               \"NaN\", \"nan\", \"-\", \"--\", \"?\", \"\", \"  \"}\n",
    "\n",
    "def replace_nulls(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).strip()\n",
    "    if s in NULL_VALUES or s == \"\":\n",
    "        return np.nan\n",
    "    return val\n",
    "\n",
    "df = df.map(replace_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Strip leading/trailing whitespace from all string cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 2: Stripping whitespace from string columns...\")\n",
    "\n",
    "def strip_whitespace(val):\n",
    "    if isinstance(val, str):\n",
    "        return val.strip()\n",
    "    return val\n",
    "\n",
    "df = df.map(strip_whitespace)\n",
    "\n",
    "# Re-apply null check after stripping (catches \"   \" cases)\n",
    "df = df.map(lambda x: np.nan if (isinstance(x, str) and x.strip() == \"\") else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 3: Removing duplicates...\")\n",
    "before = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"  Removed {before - len(df)} duplicate rows \u2192 {len(df)} rows remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalise categorical / text columns to consistent casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 4: Normalising casing in categorical columns...\")\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"difficulty_label\",       # Easy / Medium / Hard / Very Easy / Very Hard\n",
    "    \"difficulty_label_5\",     # same set\n",
    "    \"discrimination_quality\", # Good / Acceptable / Poor / Excellent\n",
    "    \"question_quality\",       # Good / Acceptable / Poor / Excellent\n",
    "    \"source\",                 # original / synthetic\n",
    "    \"CorrectAnswer\",          # A / B / C / D\n",
    "]\n",
    "\n",
    "for col in CATEGORICAL_COLS:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x).strip().title() if pd.notna(x) else x)\n",
    "\n",
    "# SubjectName and ConstructName \u2192 Title Case (fix ALL-CAPS / all-lower variants)\n",
    "for col in [\"SubjectName\", \"ConstructName\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x).strip().title() if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cast numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 5: Coercing columns to correct numeric types...\")\n",
    "\n",
    "# Float columns\n",
    "FLOAT_COLS = [\n",
    "    \"avg_word_length\", \"latex_density\", \"vocab_richness\", \"text_complexity_score\",\n",
    "    \"avg_answer_length\", \"answer_length_variance\",\n",
    "    \"pct_correct\", \"pct_chose_A\", \"pct_chose_B\", \"pct_chose_C\", \"pct_chose_D\",\n",
    "    \"avg_response_time_sec\", \"std_response_time_sec\",\n",
    "    \"difficulty_p_value\", \"irt_b_param\", \"irt_a_param\",\n",
    "    \"point_biserial_corr\", \"discrimination_index\",\n",
    "    \"p_value_upper27\", \"p_value_lower27\",\n",
    "    \"SubjectId\",\n",
    "]\n",
    "\n",
    "# Integer columns (stored as float after coercion since NaNs exist)\n",
    "INT_COLS = [\n",
    "    \"ConstructId\",\n",
    "    \"num_misconceptions\", \"has_misconception\",\n",
    "    \"MisconceptionAId\", \"MisconceptionBId\", \"MisconceptionCId\", \"MisconceptionDId\",\n",
    "    \"text_length\", \"word_count\", \"sentence_count\",\n",
    "    \"latex_command_count\", \"has_latex\",\n",
    "    \"math_operator_count\", \"number_count\",\n",
    "    \"answer_a_length\", \"answer_b_length\", \"answer_c_length\", \"answer_d_length\",\n",
    "    \"has_advanced_terms\", \"has_algebra_terms\", \"has_geometry_terms\", \"has_stats_terms\",\n",
    "    \"subject_difficulty_tier\", \"construct_frequency\",\n",
    "    \"n_students_attempted\", \"n_correct_responses\", \"n_incorrect_responses\",\n",
    "    \"difficulty_numeric\", \"OriginalQuestionId\",\n",
    "]\n",
    "\n",
    "for col in FLOAT_COLS:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "for col in INT_COLS:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Remove / cap outliers using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 6: Capping outliers using IQR (1.5\u00d7 rule)...\")\n",
    "\n",
    "OUTLIER_COLS = [\n",
    "    \"pct_correct\", \"avg_response_time_sec\", \"std_response_time_sec\",\n",
    "    \"difficulty_p_value\", \"irt_b_param\", \"irt_a_param\",\n",
    "    \"n_students_attempted\", \"text_complexity_score\",\n",
    "    \"point_biserial_corr\", \"discrimination_index\",\n",
    "]\n",
    "\n",
    "outlier_report = {}\n",
    "for col in OUTLIER_COLS:\n",
    "    if col not in df.columns:\n",
    "        continue\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    flagged = df[col].notna() & ((df[col] < lower) | (df[col] > upper))\n",
    "    outlier_report[col] = int(flagged.sum())\n",
    "    df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "print(\"  Outliers capped per column:\")\n",
    "for k, v in outlier_report.items():\n",
    "    print(f\"    {k}: {v} values capped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Enforce domain-specific constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 7: Enforcing domain constraints...\")\n",
    "\n",
    "# Percentages must be 0\u2013100\n",
    "for col in [\"pct_correct\", \"pct_chose_A\", \"pct_chose_B\", \"pct_chose_C\", \"pct_chose_D\",\n",
    "            \"p_value_upper27\", \"p_value_lower27\", \"difficulty_p_value\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].clip(lower=0, upper=100)\n",
    "\n",
    "# Binary flags must be 0 or 1\n",
    "for col in [\"has_misconception\", \"has_latex\", \"has_advanced_terms\",\n",
    "            \"has_algebra_terms\", \"has_geometry_terms\", \"has_stats_terms\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].where(df[col].isin([0.0, 1.0, np.nan]), other=np.nan)\n",
    "\n",
    "# Counts must be non-negative\n",
    "for col in [\"num_misconceptions\", \"text_length\", \"word_count\", \"sentence_count\",\n",
    "            \"latex_command_count\", \"math_operator_count\", \"number_count\",\n",
    "            \"n_students_attempted\", \"n_correct_responses\", \"n_incorrect_responses\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].where(df[col].isna() | (df[col] >= 0), other=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final dtype cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 8: Final dtype assignment...\")\n",
    "\n",
    "# Downcast int cols to Int64 (nullable integer) for clean display\n",
    "for col in INT_COLS:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.array(df[col], dtype=pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"exam_dataset_50k_cleaned.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n\u2705 Cleaning complete!\")\n",
    "print(f\"   Final shape  : {df.shape}\")\n",
    "print(f\"   Output file  : {output_path}\")\n",
    "print(f\"\\nMissing value summary (top 10 cols with most NaNs):\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10).to_string())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}