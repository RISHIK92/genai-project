# Exam Question Difficulty Predictor

### Intelligent Question Complexity Analysis via Feature Engineering & XGBoost

[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-Supported-FF4B4B?style=flat-square&logo=streamlit&logoColor=white)](https://streamlit.io)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0%2B-0F9D58?style=flat-square&logo=xgboost&logoColor=white)](https://xgboost.readthedocs.io/)

[Overview](#-overview) Â· [Architecture](#-system-architecture) Â· [Quickstart](#-quickstart) Â· [Models](#-models) Â· [Results](#-results) Â· [Application](#-application)

---

## ğŸ¯ Overview

Educators, instructional designers, and testing organizations spend countless manual hours evaluating the difficulty and quality of examination questions. A misjudged question can skew test results and inaccurately measure student proficiency.

The **Exam Question Difficulty Predictor** acts as an automated "first pass" quality assurance tool. It is an end-to-end, production-structured ML pipeline that takes raw question text (including LaTeX and math symbols) and instantly predicts how difficult it will be for students.

It predicts both a **continuous difficulty index** (p-value from 0.0 to 1.0) and a **categorical difficulty tier** (Easy, Medium, Hard). Two XGBoost model variants are deployed â€” one for **pre-exam** analysis (text-only) and one for **post-exam** analysis (all features).

### Problem Statement

| Challenge                      | Scale                         |
| ------------------------------ | ----------------------------- |
| Manual verification bottleneck | Hours spent per exam          |
| Dataset size                   | 50,000 preprocessed questions |
| Evaluation targets             | Continuous (P-value) & Tiers  |
| Structural complexity          | Text, LaTeX, Math Operators   |

---

## ğŸ— System Architecture

The project functions across three main sectors: data processing, model building, and real-time application inference.

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EXAM QUESTION DIFFICULTY PREDICTOR SYSTEM                             â”‚
â”‚                     Intelligent Question Complexity Analysis                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


                                    DATA SOURCE
                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                             exam_dataset_50k_unclean.csv
                          (Question Text + Answers + Metadata)


â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• TRAINING PIPELINE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Data Loading     â”‚
        â”‚ clean_dataset.ipynbâ”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              Preprocessing               â”‚
        â”‚------------------------------------------â”‚
        â”‚ â€¢ Standardize NULLs (N/A, none, ?, --)   â”‚
        â”‚ â€¢ Strip whitespaces & casing normalizer  â”‚
        â”‚ â€¢ Deduplication                          â”‚
        â”‚ â€¢ Enforce domain constraints (0-100%)    â”‚
        â”‚ â€¢ Outlier capping (IQR method)           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              Machine Learning Models               â”‚
        â”‚----------------------------------------------------â”‚
        â”‚  Pre-Exam (Text-Only)  â”‚  Post-Exam (All Features) â”‚
        â”‚  xgboost_pre_exam/     â”‚  xgboost_post_exam/       â”‚
        â”‚  25 features           â”‚  30 features              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Model Persistence              â”‚
        â”‚  xgb_reg_model_A.json  (pre-exam)      â”‚
        â”‚  xgb_clf_model_A.json  (pre-exam)      â”‚
        â”‚  xgb_all_reg_model_B.json (post-exam)  â”‚
        â”‚  xgb_all_clf_model_B.json (post-exam)  â”‚
        â”‚  xgb_text_model.pkl / xgb_all_model.pklâ”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•



â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• INFERENCE PIPELINE â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

        User Input (Streamlit UI via streamlit/app.py)
        (Question Text + Answer Options + Tier + Post-Admin Stats)
                    â”‚
                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Load Saved Models  â”‚
        â”‚ files/*.json       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        Feature Engineering (NLP)         â”‚
        â”‚     streamlit/feature_extractor.py       â”‚
        â”‚------------------------------------------â”‚
        â”‚ â€¢ Lexical Stats (Word & Sentence counts) â”‚
        â”‚ â€¢ Math Ops & LaTeX Density               â”‚
        â”‚ â€¢ Vocabulary Richness                    â”‚
        â”‚ â€¢ Domain Terms (Algebra, Stats, Calc)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            Prediction Engine             â”‚
        â”‚------------------------------------------â”‚
        â”‚ â€¢ xgb.DMatrix(features)                  â”‚
        â”‚ â€¢ predict_proba()                        â”‚
        â”‚ â€¢ Heuristic Bias (Subject Tier Nudge)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Difficulty Metrics Output     â”‚
        â”‚------------------------------------â”‚
        â”‚ â€¢ Predicted Class (Easy/Med/Hard)  â”‚
        â”‚ â€¢ Difficulty Index (p-value)       â”‚
        â”‚ â€¢ Confidence / Probabilities Plot  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“‚ Repository Structure

```
genai-project/
â”œâ”€â”€ README.md                         # â† You are here
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”‚
â”œâ”€â”€ streamlit/                        # Streamlit web application
â”‚   â”œâ”€â”€ app.py                        # Main application (3 pages)
â”‚   â””â”€â”€ feature_extractor.py          # 25-feature extraction module
â”‚
â”œâ”€â”€ files/                            # Serialised model artefacts
â”‚   â”œâ”€â”€ xgb_reg_model_A.json          # XGBoost Regressor (text-only, pre-exam)
â”‚   â”œâ”€â”€ xgb_clf_model_A.json          # XGBoost Classifier (text-only, pre-exam)
â”‚   â”œâ”€â”€ xgb_text_model.pkl            # LabelEncoder for pre-exam models
â”‚   â”œâ”€â”€ xgb_all_reg_model_B.json      # XGBoost Regressor (all features, post-exam)
â”‚   â”œâ”€â”€ xgb_all_clf_model_B.json      # XGBoost Classifier (all features, post-exam)
â”‚   â””â”€â”€ xgb_all_model.pkl             # LabelEncoder for post-exam models
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ clean_dataset.ipynb           # Data preprocessing notebook
â”‚   â”œâ”€â”€ visualize_results.ipynb       # Visualisation notebook
â”‚   â”œâ”€â”€ compare/
â”‚   â”‚   â””â”€â”€ compare.ipynb             # Side-by-side model comparison
â”‚   â”œâ”€â”€ xgboost_pre_exam/
â”‚   â”‚   â””â”€â”€ xgboost_pre_exam.ipynb    # Pre-exam (text-only) model training
â”‚   â””â”€â”€ xgboost_post_exam/
â”‚       â””â”€â”€ xgboost_post_exam.ipynb   # Post-exam (all features) model training
â”‚
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ report.tex                    # Full LaTeX technical report
â”‚   â””â”€â”€ report.pdf                    # Compiled PDF report
â”‚
â”œâ”€â”€ raw_dataset/
â”‚   â””â”€â”€ exam_dataset_50k_unclean.csv  # Original uncleaned data
â””â”€â”€ cleaned_dataset/
    â””â”€â”€ exam_dataset_50k_cleaned.csv  # Cleaned dataset
```

---

## ğŸš€ Quickstart

### 1. Clone & enter the repo

```bash
git clone <your-repo-link>
cd genai-project
```

### 2. Set up environment

```bash
python3 -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Launch the app

```bash
streamlit run streamlit/app.py
# Opens at http://localhost:8501
```

### 4. Train models (optional)

Open the notebooks in `notebooks/xgboost_pre_exam/` or `notebooks/xgboost_post_exam/` and run all cells. Trained models will be saved to `files/`.

---

## ğŸ§  Models

Two XGBoost model variants are deployed, each targeting a different stage of the exam lifecycle:

### Pre-Exam Model (Text-Only)

- **Use case:** Predict difficulty **before** the exam is administered
- **Features:** 25 text-derived features (lexical, LaTeX, domain terms, answer complexity)
- **Model files:** `xgb_reg_model_A.json`, `xgb_clf_model_A.json`, `xgb_text_model.pkl`

### Post-Exam Model (All Features)

- **Use case:** Predict difficulty **after** a pilot administration
- **Features:** 30 features (25 text + 5 post-admin: response time, discrimination index, IRT params)
- **Model files:** `xgb_all_reg_model_B.json`, `xgb_all_clf_model_B.json`, `xgb_all_model.pkl`

---

## ğŸ“Š Results

| Metric            | Pre-Exam (Text-Only) | Post-Exam (All Features) |
| ----------------- | -------------------- | ------------------------ |
| **MAE**           | 0.0772               | **0.0162**               |
| **RMSE**          | 0.0983               | **0.0227**               |
| **RÂ² Score**      | 0.5693               | **0.9761**               |
| **Accuracy**      | 83.34%               | **95.34%**               |
| **F1 (weighted)** | 0.80                 | **0.95**                 |

> **Note:** The post-exam model dramatically outperforms the pre-exam model because post-administration features (response time, discrimination index) are strong proxies for difficulty. However, these features are only available after students have taken the exam.

---

## ğŸ•¹ï¸ Application

The Streamlit app (`streamlit/app.py`) provides **three pages**:

### 1. Post-Exam Analysis

Enter question text, answer options, metadata, **and** post-administration statistics (response time, discrimination index, IRT parameters) to get the highest-accuracy predictions.

### 2. Pre-Exam Analysis

Enter only question text, answer options, and metadata. No post-admin data required â€” ideal for evaluating questions **before** they go live.

### 3. About the Model

Side-by-side comparison cards for both models, feature pipeline documentation, training details, and known limitations.

---

## ğŸš¦ Limitations

- **Language:** Optimised for English-language mathematics questions only.
- **No Visual Understanding:** Cannot interpret images, diagrams, or graphs.
- **Class Imbalance:** The dataset is ~80% Easy questions, leading to low recall for Hard questions in the pre-exam model.
- **Synthetic Data:** Training data includes synthetic augmentations; unusual real-world formatting may reduce confidence.

---

## ğŸ“„ Report

A comprehensive LaTeX technical report is available in `report/`:

- **Source:** `report/report.tex`
- **Compiled:** `report/report.pdf` (16 pages)

Covers: introduction, dataset, feature engineering, model architecture, training, results comparison, system architecture, application interface, heuristic adjustment, limitations, and future work.

---

## ğŸš€ Future Work â€” Milestone 2 (Agentic AI)

- **LLM Reasoning:** Leverage Gemini/GPT to solve questions step-by-step and measure conceptual complexity.
- **RAG for Curriculum Alignment:** Retrieval-Augmented Generation against educational standards.
- **Multi-Modal Processing:** Vision-Language Models for diagram-dependent questions.
- **Iterative Feedback Loops:** Agentic workflows simulating student failure modes.

---
